{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["6xiTrAxuAtfs","xrrp9aczAw0S"],"gpuType":"T4","authorship_tag":"ABX9TyNCQnTJD947f/6xOExZiSCV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9b9ZO7ukrwD","executionInfo":{"status":"ok","timestamp":1684489372132,"user_tz":-120,"elapsed":6409,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"fc22683d-5ca2-43b0-a0c3-236852da35a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nlpaug\n","  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.22.4)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.27.1)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n","Installing collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n"]}],"source":["pip install nlpaug"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/MyDrive/startTalking_main\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iLlblSeHlF-l","executionInfo":{"status":"ok","timestamp":1684489990409,"user_tz":-120,"elapsed":3551,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"abc23e32-03c4-4443-a20e-29c7a157a66c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","from data_loader.data_loaders import ShakespearePlaysLoader\n","from models.models import LSTMModel, RNNModel\n","from trainers.trainer import ModelTrainer\n","import torch.nn as nn\n","from tqdm import tqdm\n","#from test import Evaluater\n","from utils.augmenter import TextAugmenter\n","from utils.test import Evaluater"],"metadata":{"id":"BJDUEJYulMdp","executionInfo":{"status":"ok","timestamp":1684489990412,"user_tz":-120,"elapsed":20,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Hyperparameters\n","input_size = 100\n","hidden_size = 256\n","embedding_size = 100\n","num_layers = 1\n","batch_size = 64\n","num_epochs = 2\n","learning_rate = 0.001"],"metadata":{"id":"1CSXi87YlWtD","executionInfo":{"status":"ok","timestamp":1684489990413,"user_tz":-120,"elapsed":19,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Load and preprocess data\n","dataset_dir = './data/ShakespearePlays/'\n","data_processor_char = ShakespearePlaysLoader(dataset_dir, level='char')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTNhkD6VmC-A","executionInfo":{"status":"ok","timestamp":1684489990414,"user_tz":-120,"elapsed":18,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"4e769503-1868-48af-c2d1-aa996c203088"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading Shakespeare Plays...\n"]}]},{"cell_type":"code","source":["text_char_ids, char_to_id, id_to_char, vocab_size = data_processor_char.preprocess_char_level()\n","dataset = data_processor_char.create_dataset(text_char_ids[:100050])\n","train_loader, val_loader, test_loader = data_processor_char.create_loaders(dataset, 0.8, 0.1, 50)\n","\n","print(\"data loaded\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10kbTzfEnBfP","executionInfo":{"status":"ok","timestamp":1684446924293,"user_tz":-120,"elapsed":2810,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"13cdb2fc-a297-4647-ac3b-b79f3cf36850"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessing data...\n","Building character vocabulary...\n","Creating dataset...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 100000/100000 [00:00<00:00, 143585.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["data loaded\n"]}]},{"cell_type":"markdown","source":["## Train LSTM"],"metadata":{"id":"6xiTrAxuAtfs"}},{"cell_type":"code","source":["# Initialize the LSTM model with an embedding layer\n","model = LSTMModel(input_size, hidden_size, vocab_size, num_layers, embedding_size)\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define the loss function, learning rate, and optimizer\n","criterion = nn.CrossEntropyLoss()  # Ignore padding tokens\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","trainer = ModelTrainer(model, train_loader, criterion, optimizer, device)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    print(\"starting epoch\", epoch+1)\n","    loss = trainer.train()\n","    validation_loss = trainer.evaluate(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFClaQiyo_18","executionInfo":{"status":"ok","timestamp":1684429722343,"user_tz":-120,"elapsed":619820,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"e650fcc2-6a52-4b98-bf7a-2ff1631eb83d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["starting epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1600/1600 [04:55<00:00,  5.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2, Loss: 1.5986, Validation Loss: 1.2587\n","starting epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1600/1600 [04:57<00:00,  5.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/2, Loss: 1.0823, Validation Loss: 0.9282\n"]}]},{"cell_type":"code","source":["## Evaluate the model\n","\n","test_loss = trainer.evaluate(test_loader)\n","print(f\"After 2 Epochs of Training, Testing Loss is: {test_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-iAmDLb9207x","executionInfo":{"status":"ok","timestamp":1684430145552,"user_tz":-120,"elapsed":13410,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"c150a115-2dfc-49cf-b228-739db5a9d387"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["After 2 Epochs of Training, Testing Loss is: 0.9253\n"]}]},{"cell_type":"code","source":["\n","\n","evaluater = Evaluater(model, device)\n","\n","perplexity = evaluater.calculate_perplexity(test_loader, criterion)\n","print('Perplexity:', perplexity)\n","\n","seed_text = \"Start a discussion about coffee\"\n","gen_length = 2000\n","\n","generated_text = evaluater.generate_text(seed_text, gen_length, char_to_id, id_to_char, 'char', device, temperature=1, top_p=0)\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8B18fTLE1sJg","executionInfo":{"status":"ok","timestamp":1684431966118,"user_tz":-120,"elapsed":15395,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"20a3ad13-ff23-4840-8310-d378b76c6479"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity: 2.522712044019018\n","Start a discussion about coffees. Ay: but you look son?\n","\n","First Senator:\n","Ay, heart-planes?\n","\n","CORIOLANUS:\n","It in things at on\n","were used my country: beyond wish him, ever\n","sine antrict in cholens greeded, I trop'd the oak ow there?\n","Of Cominius!\n","Leat's dear the people confound, in his country;\n","For they now newe have, and life!\n","All what should the high off o'er-power of his to:\n","him preciustion; which else we have ment, there\n","but therefort what he vile their confirs.\n","\n","AEdile:\n","If any wholedield;\n","Ence did with your people! Hoo! he's will.\n","\n","MENENIUS:\n","Sir, so, welcome put\n","The heart of Cuill be soothing membends?\n","\n","Senators, &C:oo mockery: the Volsces\n","With cushions we have people,\n","And venough mory points without as done,\n","I'll hath me-bretles tongues that love those these have veel\n","your honour of their oncers; that is not some poor\n","singrous countryes for the Volsces, fluind?\n","Now stablish yet flag, that authy; he gates, years, Marcius,\n","Away, speak, I will not so speak or noble we'll strengfes' countrying: he worshonour\n","Than less he with us.\n","\n","BRUTUS:\n","And you do discorn the people;\n","In loves my nobility, and your valour so purn atterfound\n","My lord me: lease you have now off the world\n","I' the lips and begar it, as I, throng his pliery;\n","from him head Rome his dided five, you have breath\n","Of all ut ourtendreds couls of to our tience,\n","Canaton's house word.\n","Our Jupius was Marcius as so.\n","\n","Citizens:\n","Come, tell you you\n","not doth, nor more that, when either tellume way.\n","\n","First Senator:\n","No more of us hath;\n","'This Menenius,--o, no fully dignonour never be the man;\n","God my mail, I would be consul?\n","\n","MENENIUS:\n","One wall.\n","\n","MENENIUS:\n","\n","SICINIUS:\n","Have my death.\n","\n","VALERIA:\n","On prayers.\n","Would the stouth. Nay, mother.\n","\n","First Citizen:\n","The gods assemments.\n","\n","MENENIUS:\n","Ay, come.\n","\n","First Officer:\n","Finnery, sporth upon him!\n","\n","MARCIUS:\n","I'll dive my care of us,\n","Lesser have them me, so, he has held him, some up\n","When more voices he: one on?\n","\n","MENENIUS:\n","Are yet not wholenoubd as the follown: of one fallly\n","To kee must done if I lave's since their race,\n","You have\n"]}]},{"cell_type":"markdown","source":["## Train RNN"],"metadata":{"id":"xrrp9aczAw0S"}},{"cell_type":"code","source":["# Initialize the LSTM model with an embedding layer\n","model = RNNModel(input_size, hidden_size, vocab_size, num_layers, embedding_size)\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define the loss function, learning rate, and optimizer\n","criterion = nn.CrossEntropyLoss()  # Ignore padding tokens\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","trainer = ModelTrainer(model, train_loader, criterion, optimizer, device, number_states=1)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    print(\"starting epoch\", epoch+1)\n","    loss = trainer.train()\n","    validation_loss = trainer.evaluate(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1LR370T3HaZ","executionInfo":{"status":"ok","timestamp":1684447111469,"user_tz":-120,"elapsed":174260,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"821c89bd-3538-4dac-cc1e-8d3c89adb765"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["starting epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1600/1600 [01:24<00:00, 18.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2, Loss: 1.5939, Validation Loss: 1.3047\n","starting epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1600/1600 [01:21<00:00, 19.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/2, Loss: 1.1873, Validation Loss: 1.0943\n"]}]},{"cell_type":"code","source":["# Initialize the LSTM model with an embedding layer\n","model = RNNModel(input_size, hidden_size, vocab_size, num_layers, embedding_size)\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define the loss function, learning rate, and optimizer\n","criterion = nn.CrossEntropyLoss()  # Ignore padding tokens\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","trainer = ModelTrainer(model, train_loader, criterion, optimizer, device, number_states=1)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    print(\"starting epoch\", epoch+1)\n","    loss = trainer.train()\n","    validation_loss = trainer.evaluate(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")"],"metadata":{"id":"HSC81VDdAz8h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684441901692,"user_tz":-120,"elapsed":18343,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"abf24adb-1912-4329-cb54-0ca6a54e878e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["starting epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1600/1600 [00:06<00:00, 242.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2, Loss: 1.5916, Validation Loss: 1.3084\n","starting epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1600/1600 [00:05<00:00, 314.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/2, Loss: 1.1906, Validation Loss: 1.0951\n"]}]},{"cell_type":"code","source":["## Evaluate the model\n","\n","test_loss = trainer.evaluate(test_loader)\n","print(f\"After 2 Epochs of Training, Testing Loss is: {test_loss:.4f}\")"],"metadata":{"id":"zgQkdiHWA4Gn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684441902310,"user_tz":-120,"elapsed":637,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"8919f597-bbb2-4bd3-e291-fe866a4f0fdc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["After 2 Epochs of Training, Testing Loss is: 1.0937\n"]}]},{"cell_type":"code","source":["evaluater = Evaluater(model, device, number_states=1)\n","\n","perplexity = evaluater.calculate_perplexity(test_loader, criterion)\n","print('Perplexity:', perplexity)\n","\n","seed_text = \"Start a discussion about coffee\"\n","gen_length = 2000\n","\n","generated_text = evaluater.generate_text(seed_text, gen_length, char_to_id, id_to_char, 'char', device, temperature=1, top_p=0)\n","print(generated_text)"],"metadata":{"id":"TfitAHm4A_69","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684441907599,"user_tz":-120,"elapsed":1851,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"1c8932e4-170f-4e05-937e-3f3232fcbb62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity: 2.9851783948402133\n","Start a discussion about coffee him be\n","Catuses:\n","Fas no more of that: ever sunger\n","hofest you? or us than they shall as it was with senace, have your gora wonders.\n","\n","AUFIDIUS:\n","Condent-blied against ought follow to beg oaker.\n","\n","CORIOLANUS:\n","And tradume have reined,\n","As we shall go petinius, he would and Tace: and be rotberse spions him jagany, in every minnter's\n","He his brain'd friends; we'll hear, my distabuol, see his reace, hey the fliers,\n","troth, in 'tis his find you; heals, there's at his country\n","you grows I stand flator:\n","Nather senator:\n","Agave him on\n","To our hearm at one poor of yiuld invines,\n","Let fough actions: tale,\n","I may, all his one speak.\n","Come, lack'd of, aVAls to threess to Rome my 'lforthits; and basting,\n","The blood\n","Their bay, I would unders,\n","Those clught; when, strong\n","And from he came modest gillip of thy absenter reation'd of hone, lets\n","He's say your voices more nettle stum' than dous blood won.\n","\n","MENENIUS:\n","Thy foon,' fixed anot the greater: you have lits to stard, but by trenfore in hearings,\n","It shall be so visil of must envee, and slike a ce-lovets me like, I may the veamp try eass of these heart, with such his mulame to her what stame had\n","you shall intering.\n","\n","SICINIUS:\n","Halk, I will pray you? Though speak'd;\n","Pray you to see the tribunes\n","My sounds hears taken makely--\n","\n","SICINIUS:\n","I that, thus too letter her.\n","\n","SICINIUS:\n","Sir, go quaked ifte one this promise.\n","\n","SIOLANUS:\n","Either Note to so, I knem, let's an issus\n","The love's good madam, the Volsces wills,\n","And what he hazard\n","With success the sure. How done, I am hight to up.\n","\n","VOLUMNIA:\n","He endle remain\n","Fakeng 'em! I god a one lived at leads on revoke fliedry'\n","Has hear do.\n","\n","VOLUMNIA:\n","Every for\n","ye'd all other sway you.\n","\n","SICINIUS:\n","'Pevacy disdait\n","Show\n","When we stall:\n","'tis side, and the town.\n","\n","VIRGILIA:\n","O mark thunders,\n","Anowon, ye is,\n","and to right spare it. Go rot--never bands! Truth al-honours made wonger,\n","Then\n","To you to stawnt all along lawes,\n","When I charge to knee whose sently\n","Strare themsings\n","lewes berear, when you noble with his swards meanst you bey h\n"]}]},{"cell_type":"markdown","source":["# Word Level\n"],"metadata":{"id":"OV_PA0q7Ag28"}},{"cell_type":"code","source":["data_processor_word = ShakespearePlaysLoader(dataset_dir, level='word')"],"metadata":{"id":"fBxrgAexAqA0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684490013465,"user_tz":-120,"elapsed":3130,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"d5476178-eab8-488e-9240-3cd12893224e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading Shakespeare Plays...\n"]}]},{"cell_type":"code","source":["text_word_ids, embedding_matrix, vocab_size = data_processor_word.preprocess_word_level()\n","dataset = data_processor_word.create_dataset(text_word_ids[:1050])\n","train_loader, val_loader, test_loader = data_processor_word.create_loaders(dataset, 0.8, 0.1, 50)\n","\n","print(\"data loaded\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cqna2ymApDsk","executionInfo":{"status":"ok","timestamp":1684490022098,"user_tz":-120,"elapsed":4702,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"137ca3c5-4274-4197-95e3-2891de491bde"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessing data...\n","Building word vocabulary...\n","Creating dataset...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [00:00<00:00, 19563.35it/s]"]},{"output_type":"stream","name":"stdout","text":["data loaded\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["data_processor_word.id_to_word['1087']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"S0EAjjkfZXBX","executionInfo":{"status":"ok","timestamp":1684490027642,"user_tz":-120,"elapsed":364,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"d0d7435e-52a6-4715-c5ba-3ba6859dad1d"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'here'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## Train RNN"],"metadata":{"id":"gseIIO4O7Orz"}},{"cell_type":"code","source":["len(text_word_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qpi9XCIuCjux","executionInfo":{"status":"ok","timestamp":1684489913297,"user_tz":-120,"elapsed":1466,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"5a76b85e-53dc-45e4-db91-bf23956f7c1b"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["202651"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["embedding_matrix.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNSxiG2-CQRp","executionInfo":{"status":"ok","timestamp":1684489918021,"user_tz":-120,"elapsed":8,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"a9163b20-5658-4bdb-8780-ea0ad8af2cca"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([25672, 300])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Initialize the LSTM model with an embedding layer\n","model = RNNModel(input_size, hidden_size, vocab_size, num_layers, embedding_matrix.size()[1], embedding_matrix, level='word')\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define the loss function, learning rate, and optimizer\n","criterion = nn.CrossEntropyLoss()  # Ignore padding tokens\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","trainer = ModelTrainer(model, train_loader, criterion, optimizer, device, number_states=1)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    print(\"starting epoch\", epoch+1)\n","    loss = trainer.train()\n","    validation_loss = trainer.evaluate(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EI28MLTkbi14","executionInfo":{"status":"ok","timestamp":1684490140207,"user_tz":-120,"elapsed":99442,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"a4e06c7f-9d5d-4a17-ed29-dc0ee6c77d97"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["starting epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:48<00:00,  3.00s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2, Loss: 8.2636, Validation Loss: 6.1227\n","starting epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:46<00:00,  2.89s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/2, Loss: 5.9401, Validation Loss: 5.8611\n"]}]},{"cell_type":"code","source":["## Evaluate the model\n","\n","test_loss = trainer.evaluate(test_loader)\n","print(f\"After 2 Epochs of Training, Testing Loss is: {test_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MSOYUPMb9_v","executionInfo":{"status":"ok","timestamp":1684490154411,"user_tz":-120,"elapsed":2394,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"75895a58-d727-42b3-e227-5a7fce6c90da"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["After 2 Epochs of Training, Testing Loss is: 5.8695\n"]}]},{"cell_type":"code","source":["evaluater = Evaluater(model, device, number_states=1)\n","\n","perplexity = evaluater.calculate_perplexity(test_loader, criterion)\n","print('Perplexity:', perplexity)\n","\n","seed_text = \"Start a discussion about coffee\"\n","gen_length = 100\n","\n","generated_text = evaluater.generate_text(seed_text, gen_length, data_processor_word.word_to_id, data_processor_word.id_to_word, 'word', device, temperature=1, top_p=0)\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a9tBWbQZcBVt","executionInfo":{"status":"ok","timestamp":1684490202827,"user_tz":-120,"elapsed":2838,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"f7901eab-a8aa-47f5-fea2-11c1c25db239"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity: 354.0629242404186\n","Start a discussion about coffee if Who it belly's way we Consider Citizen: it too. What a patricians store-house helps them, you. for Either this show in is they A whole what more maliciously. But, thus remember, especially First stale were other That viand, receipt; up, shall being state, you The loved As rash in they if altitude a patricians the As you'll rich, come. with his and Citizen: come. thus members, mother well is, Citizen: thus must shall intend a lungs, of MENENIUS: Citizen: Citizen: which to Our poor their we speak, to As have First that is in they Appear shouts speak, MENENIUS:\n"]}]},{"cell_type":"code","source":["# Initialize the LSTM model with an embedding layer\n","model = RNNModel(input_size, hidden_size, vocab_size, num_layers, embedding_matrix.size()[1], embedding_matrix, level='word')\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define the loss function, learning rate, and optimizer\n","criterion = nn.CrossEntropyLoss()  # Ignore padding tokens\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","trainer = ModelTrainer(model, train_loader, criterion, optimizer, device, number_states=1)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    print(\"starting epoch\", epoch+1)\n","    loss = trainer.train()\n","    validation_loss = trainer.evaluate(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684460979497,"user_tz":-120,"elapsed":9323702,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"1251a544-40d2-4597-92c7-cdf87a70a537","id":"ZyEQYyZH7Or0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["starting epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1600/1600 [1:15:08<00:00,  2.82s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/2, Loss: 4.7133, Validation Loss: 1.8526\n","starting epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1600/1600 [1:13:40<00:00,  2.76s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/2, Loss: 0.9299, Validation Loss: 0.4809\n"]}]},{"cell_type":"code","source":["## Evaluate the model\n","\n","test_loss = trainer.evaluate(test_loader)\n","print(f\"After 2 Epochs of Training, Testing Loss is: {test_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684461170335,"user_tz":-120,"elapsed":190855,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"190719bd-cb7a-49a4-f359-384d725c51d9","id":"vk8nGXMX7Or1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["After 2 Epochs of Training, Testing Loss is: 0.4830\n"]}]},{"cell_type":"code","source":["evaluater = Evaluater(model, device, number_states=1)\n","\n","perplexity = evaluater.calculate_perplexity(test_loader, criterion)\n","print('Perplexity:', perplexity)\n","\n","seed_text = \"Start a discussion about coffee\"\n","gen_length = 50\n","\n","generated_text = evaluater.generate_text(seed_text, gen_length, data_processor_word.word_to_id, data_processor_word.id_to_word, 'word', device, temperature=1, top_p=0)\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"error","timestamp":1684461364941,"user_tz":-120,"elapsed":191643,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"}},"outputId":"94f4a89b-58c9-4875-9dfd-a2642e50c17e","id":"8BFhd5VJ7Or1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexity: 1.620922608377538\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-820d493aff76>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgen_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_processor_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_processor_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_to_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/startTalking_main/utils/test4.py\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(self, seed_text, gen_length, _to_id, id_to_, level, device, temperature, top_p)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;31m# Sample a word from the output probability distribution if the word is not <UNK> otherwise sample again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0mid_to_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'<UNK>'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '1087'"]}]},{"cell_type":"markdown","source":["# Byte Pair Encoding"],"metadata":{"id":"3y0Ao6n_JyNh"}},{"cell_type":"markdown","source":["# Data Augmentation"],"metadata":{"id":"mD28lvjzJePW"}},{"cell_type":"code","source":[],"metadata":{"id":"zz_8bRmhJjXS"},"execution_count":null,"outputs":[]}]}