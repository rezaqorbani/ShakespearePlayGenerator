{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6409,"status":"ok","timestamp":1684489372132,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"c9b9ZO7ukrwD","outputId":"fc22683d-5ca2-43b0-a0c3-236852da35a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nlpaug\n","  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.22.4)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.27.1)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n","Installing collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n"]}],"source":["pip install nlpaug"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3551,"status":"ok","timestamp":1684489990409,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"iLlblSeHlF-l","outputId":"abc23e32-03c4-4443-a20e-29c7a157a66c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/MyDrive/startTalking_main\")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1684489990412,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"BJDUEJYulMdp"},"outputs":[],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","from data_loader.ShakespearePlaysLoader import ShakespearePlaysLoader\n","from data_loader.CornellMovieLoader import CornellMovieLoader\n","from models.models import LSTMModel, RNNModel\n","from trainers.trainer import ModelTrainer\n","import torch.nn as nn\n","from tqdm import tqdm\n","#from test import Evaluater\n","from utils.augmenter import TextAugmenter\n","from test import Evaluater"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1684489990413,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"1CSXi87YlWtD"},"outputs":[],"source":["# Hyperparameters\n","input_size = 100\n","hidden_size = 256\n","embedding_size = 100\n","num_layers = 1\n","batch_size = 64\n","num_epochs = 2\n","learning_rate = 0.001"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1684489990414,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"cTNhkD6VmC-A","outputId":"4e769503-1868-48af-c2d1-aa996c203088"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading Shakespeare Plays...\n"]}],"source":["# Load and preprocess data\n","dataset_dir = './data/ShakespearePlays/'\n","data_processor_char = ShakespearePlaysLoader(dataset_dir, level='char')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2810,"status":"ok","timestamp":1684446924293,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"10kbTzfEnBfP","outputId":"13cdb2fc-a297-4647-ac3b-b79f3cf36850"},"outputs":[{"name":"stdout","output_type":"stream","text":["Preprocessing data...\n","Building character vocabulary...\n","Creating dataset...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 100000/100000 [00:00<00:00, 143585.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["data loaded\n"]}],"source":["text_char_ids, vocab_size = data_processor_char.preprocess_char_level()\n","char_to_id=data_processor_char.char_to_id\n","id_to_char=data_processor_char.id_to_char\n","dataset = data_processor_char.create_dataset(text_char_ids[:100050])\n","train_loader, val_loader, test_loader = data_processor_char.create_loaders(dataset, 0.8, 0.1, 50)\n","\n","print(\"data loaded\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6xiTrAxuAtfs"},"source":["## Train LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":619820,"status":"ok","timestamp":1684429722343,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"YFClaQiyo_18","outputId":"e650fcc2-6a52-4b98-bf7a-2ff1631eb83d"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1600/1600 [04:55<00:00,  5.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/2, Loss: 1.5986, Validation Loss: 1.2587\n","starting epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1600/1600 [04:57<00:00,  5.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/2, Loss: 1.0823, Validation Loss: 0.9282\n"]}],"source":["# Initialize the LSTM model with an embedding layer\n","model = LSTMModel(input_size, hidden_size, vocab_size, num_layers, embedding_size)\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define the loss function, learning rate, and optimizer\n","criterion = nn.CrossEntropyLoss()  # Ignore padding tokens\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","trainer = ModelTrainer(model, train_loader, criterion, optimizer, device)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    print(\"starting epoch\", epoch+1)\n","    loss = trainer.train()\n","    validation_loss = trainer.evaluate(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13410,"status":"ok","timestamp":1684430145552,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"-iAmDLb9207x","outputId":"c150a115-2dfc-49cf-b228-739db5a9d387"},"outputs":[{"name":"stdout","output_type":"stream","text":["After 2 Epochs of Training, Testing Loss is: 0.9253\n"]}],"source":["## Evaluate the model\n","\n","test_loss = trainer.evaluate(test_loader)\n","print(f\"After 2 Epochs of Training, Testing Loss is: {test_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15395,"status":"ok","timestamp":1684431966118,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"8B18fTLE1sJg","outputId":"20a3ad13-ff23-4840-8310-d378b76c6479"},"outputs":[{"name":"stdout","output_type":"stream","text":["Perplexity: 2.522712044019018\n","Start a discussion about coffees. Ay: but you look son?\n","\n","First Senator:\n","Ay, heart-planes?\n","\n","CORIOLANUS:\n","It in things at on\n","were used my country: beyond wish him, ever\n","sine antrict in cholens greeded, I trop'd the oak ow there?\n","Of Cominius!\n","Leat's dear the people confound, in his country;\n","For they now newe have, and life!\n","All what should the high off o'er-power of his to:\n","him preciustion; which else we have ment, there\n","but therefort what he vile their confirs.\n","\n","AEdile:\n","If any wholedield;\n","Ence did with your people! Hoo! he's will.\n","\n","MENENIUS:\n","Sir, so, welcome put\n","The heart of Cuill be soothing membends?\n","\n","Senators, &C:oo mockery: the Volsces\n","With cushions we have people,\n","And venough mory points without as done,\n","I'll hath me-bretles tongues that love those these have veel\n","your honour of their oncers; that is not some poor\n","singrous countryes for the Volsces, fluind?\n","Now stablish yet flag, that authy; he gates, years, Marcius,\n","Away, speak, I will not so speak or noble we'll strengfes' countrying: he worshonour\n","Than less he with us.\n","\n","BRUTUS:\n","And you do discorn the people;\n","In loves my nobility, and your valour so purn atterfound\n","My lord me: lease you have now off the world\n","I' the lips and begar it, as I, throng his pliery;\n","from him head Rome his dided five, you have breath\n","Of all ut ourtendreds couls of to our tience,\n","Canaton's house word.\n","Our Jupius was Marcius as so.\n","\n","Citizens:\n","Come, tell you you\n","not doth, nor more that, when either tellume way.\n","\n","First Senator:\n","No more of us hath;\n","'This Menenius,--o, no fully dignonour never be the man;\n","God my mail, I would be consul?\n","\n","MENENIUS:\n","One wall.\n","\n","MENENIUS:\n","\n","SICINIUS:\n","Have my death.\n","\n","VALERIA:\n","On prayers.\n","Would the stouth. Nay, mother.\n","\n","First Citizen:\n","The gods assemments.\n","\n","MENENIUS:\n","Ay, come.\n","\n","First Officer:\n","Finnery, sporth upon him!\n","\n","MARCIUS:\n","I'll dive my care of us,\n","Lesser have them me, so, he has held him, some up\n","When more voices he: one on?\n","\n","MENENIUS:\n","Are yet not wholenoubd as the follown: of one fallly\n","To kee must done if I lave's since their race,\n","You have\n"]}],"source":["\n","\n","evaluater = Evaluater(model, device)\n","\n","perplexity = evaluater.calculate_perplexity(test_loader, criterion)\n","print('Perplexity:', perplexity)\n","\n","seed_text = \"Start a discussion about coffee\"\n","gen_length = 2000\n","\n","generated_text = evaluater.generate_text(seed_text, gen_length, char_to_id, id_to_char, 'char', device, temperature=1, top_p=0)\n","print(generated_text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xrrp9aczAw0S"},"source":["## Train RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174260,"status":"ok","timestamp":1684447111469,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"F1LR370T3HaZ","outputId":"821c89bd-3538-4dac-cc1e-8d3c89adb765"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1600/1600 [01:24<00:00, 18.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/2, Loss: 1.5939, Validation Loss: 1.3047\n","starting epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1600/1600 [01:21<00:00, 19.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/2, Loss: 1.1873, Validation Loss: 1.0943\n"]}],"source":["# Initialize the LSTM model with an embedding layer\n","model = RNNModel(input_size, hidden_size, vocab_size, num_layers, embedding_size)\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define the loss function, learning rate, and optimizer\n","criterion = nn.CrossEntropyLoss()  # Ignore padding tokens\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","trainer = ModelTrainer(model, train_loader, criterion, optimizer, device, number_states=1)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    print(\"starting epoch\", epoch+1)\n","    loss = trainer.train()\n","    validation_loss = trainer.evaluate(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18343,"status":"ok","timestamp":1684441901692,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"HSC81VDdAz8h","outputId":"abf24adb-1912-4329-cb54-0ca6a54e878e"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1600/1600 [00:06<00:00, 242.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/2, Loss: 1.5916, Validation Loss: 1.3084\n","starting epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1600/1600 [00:05<00:00, 314.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/2, Loss: 1.1906, Validation Loss: 1.0951\n"]}],"source":["# Initialize the LSTM model with an embedding layer\n","model = RNNModel(input_size, hidden_size, vocab_size, num_layers, embedding_size)\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define the loss function, learning rate, and optimizer\n","criterion = nn.CrossEntropyLoss()  # Ignore padding tokens\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","trainer = ModelTrainer(model, train_loader, criterion, optimizer, device, number_states=1)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    print(\"starting epoch\", epoch+1)\n","    loss = trainer.train()\n","    validation_loss = trainer.evaluate(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":637,"status":"ok","timestamp":1684441902310,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"zgQkdiHWA4Gn","outputId":"8919f597-bbb2-4bd3-e291-fe866a4f0fdc"},"outputs":[{"name":"stdout","output_type":"stream","text":["After 2 Epochs of Training, Testing Loss is: 1.0937\n"]}],"source":["## Evaluate the model\n","\n","test_loss = trainer.evaluate(test_loader)\n","print(f\"After 2 Epochs of Training, Testing Loss is: {test_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1851,"status":"ok","timestamp":1684441907599,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"TfitAHm4A_69","outputId":"1c8932e4-170f-4e05-937e-3f3232fcbb62"},"outputs":[{"name":"stdout","output_type":"stream","text":["Perplexity: 2.9851783948402133\n","Start a discussion about coffee him be\n","Catuses:\n","Fas no more of that: ever sunger\n","hofest you? or us than they shall as it was with senace, have your gora wonders.\n","\n","AUFIDIUS:\n","Condent-blied against ought follow to beg oaker.\n","\n","CORIOLANUS:\n","And tradume have reined,\n","As we shall go petinius, he would and Tace: and be rotberse spions him jagany, in every minnter's\n","He his brain'd friends; we'll hear, my distabuol, see his reace, hey the fliers,\n","troth, in 'tis his find you; heals, there's at his country\n","you grows I stand flator:\n","Nather senator:\n","Agave him on\n","To our hearm at one poor of yiuld invines,\n","Let fough actions: tale,\n","I may, all his one speak.\n","Come, lack'd of, aVAls to threess to Rome my 'lforthits; and basting,\n","The blood\n","Their bay, I would unders,\n","Those clught; when, strong\n","And from he came modest gillip of thy absenter reation'd of hone, lets\n","He's say your voices more nettle stum' than dous blood won.\n","\n","MENENIUS:\n","Thy foon,' fixed anot the greater: you have lits to stard, but by trenfore in hearings,\n","It shall be so visil of must envee, and slike a ce-lovets me like, I may the veamp try eass of these heart, with such his mulame to her what stame had\n","you shall intering.\n","\n","SICINIUS:\n","Halk, I will pray you? Though speak'd;\n","Pray you to see the tribunes\n","My sounds hears taken makely--\n","\n","SICINIUS:\n","I that, thus too letter her.\n","\n","SICINIUS:\n","Sir, go quaked ifte one this promise.\n","\n","SIOLANUS:\n","Either Note to so, I knem, let's an issus\n","The love's good madam, the Volsces wills,\n","And what he hazard\n","With success the sure. How done, I am hight to up.\n","\n","VOLUMNIA:\n","He endle remain\n","Fakeng 'em! I god a one lived at leads on revoke fliedry'\n","Has hear do.\n","\n","VOLUMNIA:\n","Every for\n","ye'd all other sway you.\n","\n","SICINIUS:\n","'Pevacy disdait\n","Show\n","When we stall:\n","'tis side, and the town.\n","\n","VIRGILIA:\n","O mark thunders,\n","Anowon, ye is,\n","and to right spare it. Go rot--never bands! Truth al-honours made wonger,\n","Then\n","To you to stawnt all along lawes,\n","When I charge to knee whose sently\n","Strare themsings\n","lewes berear, when you noble with his swards meanst you bey h\n"]}],"source":["evaluater = Evaluater(model, device, number_states=1)\n","\n","perplexity = evaluater.calculate_perplexity(test_loader, criterion)\n","print('Perplexity:', perplexity)\n","\n","seed_text = \"Start a discussion about coffee\"\n","gen_length = 2000\n","\n","generated_text = evaluater.generate_text(seed_text, gen_length, char_to_id, id_to_char, 'char', device, temperature=1, top_p=0)\n","print(generated_text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OV_PA0q7Ag28"},"source":["# Word Level\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3130,"status":"ok","timestamp":1684490013465,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"fBxrgAexAqA0","outputId":"d5476178-eab8-488e-9240-3cd12893224e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading Shakespeare Plays...\n"]}],"source":["data_processor_word = ShakespearePlaysLoader(dataset_dir, level='word')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4702,"status":"ok","timestamp":1684490022098,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"Cqna2ymApDsk","outputId":"137ca3c5-4274-4197-95e3-2891de491bde"},"outputs":[{"name":"stdout","output_type":"stream","text":["Preprocessing data...\n","Building word vocabulary...\n","Creating dataset...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 19563.35it/s]"]},{"name":"stdout","output_type":"stream","text":["data loaded\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["text_word_ids, embedding_matrix, vocab_size = data_processor_word.preprocess_word_level()\n","dataset = data_processor_word.create_dataset(text_word_ids[:1050])\n","train_loader, val_loader, test_loader = data_processor_word.create_loaders(dataset, 0.8, 0.1, 50)\n","\n","print(\"data loaded\")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1684490027642,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"S0EAjjkfZXBX","outputId":"d0d7435e-52a6-4715-c5ba-3ba6859dad1d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'here'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["data_processor_word.id_to_word['1087']"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gseIIO4O7Orz"},"source":["## Train RNN"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1466,"status":"ok","timestamp":1684489913297,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"Qpi9XCIuCjux","outputId":"5a76b85e-53dc-45e4-db91-bf23956f7c1b"},"outputs":[{"data":{"text/plain":["202651"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["len(text_word_ids)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684489918021,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"YNSxiG2-CQRp","outputId":"a9163b20-5658-4bdb-8780-ea0ad8af2cca"},"outputs":[{"data":{"text/plain":["torch.Size([25672, 300])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["embedding_matrix.shape"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99442,"status":"ok","timestamp":1684490140207,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"EI28MLTkbi14","outputId":"a4e06c7f-9d5d-4a17-ed29-dc0ee6c77d97"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 16/16 [00:48<00:00,  3.00s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/2, Loss: 8.2636, Validation Loss: 6.1227\n","starting epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 16/16 [00:46<00:00,  2.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/2, Loss: 5.9401, Validation Loss: 5.8611\n"]}],"source":["# Initialize the LSTM model with an embedding layer\n","model = RNNModel(input_size, hidden_size, vocab_size, num_layers, embedding_matrix.size()[1], embedding_matrix, level='word')\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define the loss function, learning rate, and optimizer\n","criterion = nn.CrossEntropyLoss()  # Ignore padding tokens\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","trainer = ModelTrainer(model, train_loader, criterion, optimizer, device, number_states=1)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    print(\"starting epoch\", epoch+1)\n","    loss = trainer.train()\n","    validation_loss = trainer.evaluate(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2394,"status":"ok","timestamp":1684490154411,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"_MSOYUPMb9_v","outputId":"75895a58-d727-42b3-e227-5a7fce6c90da"},"outputs":[{"name":"stdout","output_type":"stream","text":["After 2 Epochs of Training, Testing Loss is: 5.8695\n"]}],"source":["## Evaluate the model\n","\n","test_loss = trainer.evaluate(test_loader)\n","print(f\"After 2 Epochs of Training, Testing Loss is: {test_loss:.4f}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2838,"status":"ok","timestamp":1684490202827,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"a9tBWbQZcBVt","outputId":"f7901eab-a8aa-47f5-fea2-11c1c25db239"},"outputs":[{"name":"stdout","output_type":"stream","text":["Perplexity: 354.0629242404186\n","Start a discussion about coffee if Who it belly's way we Consider Citizen: it too. What a patricians store-house helps them, you. for Either this show in is they A whole what more maliciously. But, thus remember, especially First stale were other That viand, receipt; up, shall being state, you The loved As rash in they if altitude a patricians the As you'll rich, come. with his and Citizen: come. thus members, mother well is, Citizen: thus must shall intend a lungs, of MENENIUS: Citizen: Citizen: which to Our poor their we speak, to As have First that is in they Appear shouts speak, MENENIUS:\n"]}],"source":["evaluater = Evaluater(model, device, number_states=1)\n","\n","perplexity = evaluater.calculate_perplexity(test_loader, criterion)\n","print('Perplexity:', perplexity)\n","\n","seed_text = \"Start a discussion about coffee\"\n","gen_length = 100\n","\n","generated_text = evaluater.generate_text(seed_text, gen_length, data_processor_word.word_to_id, data_processor_word.id_to_word, 'word', device, temperature=1, top_p=0)\n","print(generated_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9323702,"status":"ok","timestamp":1684460979497,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"ZyEQYyZH7Or0","outputId":"1251a544-40d2-4597-92c7-cdf87a70a537"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1600/1600 [1:15:08<00:00,  2.82s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/2, Loss: 4.7133, Validation Loss: 1.8526\n","starting epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1600/1600 [1:13:40<00:00,  2.76s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/2, Loss: 0.9299, Validation Loss: 0.4809\n"]}],"source":["# Initialize the LSTM model with an embedding layer\n","model = RNNModel(input_size, hidden_size, vocab_size, num_layers, embedding_matrix.size()[1], embedding_matrix, level='word')\n","\n","# Move the model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define the loss function, learning rate, and optimizer\n","criterion = nn.CrossEntropyLoss()  # Ignore padding tokens\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","trainer = ModelTrainer(model, train_loader, criterion, optimizer, device, number_states=1)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    print(\"starting epoch\", epoch+1)\n","    loss = trainer.train()\n","    validation_loss = trainer.evaluate(val_loader)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}, Validation Loss: {validation_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190855,"status":"ok","timestamp":1684461170335,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"vk8nGXMX7Or1","outputId":"190719bd-cb7a-49a4-f359-384d725c51d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["After 2 Epochs of Training, Testing Loss is: 0.4830\n"]}],"source":["## Evaluate the model\n","\n","test_loss = trainer.evaluate(test_loader)\n","print(f\"After 2 Epochs of Training, Testing Loss is: {test_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":191643,"status":"error","timestamp":1684461364941,"user":{"displayName":"Zineb Senane","userId":"09805470197192868578"},"user_tz":-120},"id":"8BFhd5VJ7Or1","outputId":"94f4a89b-58c9-4875-9dfd-a2642e50c17e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Perplexity: 1.620922608377538\n"]},{"ename":"KeyError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-820d493aff76>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgen_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluater\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_processor_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_processor_word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_to_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/startTalking_main/utils/test4.py\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(self, seed_text, gen_length, _to_id, id_to_, level, device, temperature, top_p)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;31m# Sample a word from the output probability distribution if the word is not <UNK> otherwise sample again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0mid_to_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'<UNK>'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '1087'"]}],"source":["evaluater = Evaluater(model, device, number_states=1)\n","\n","perplexity = evaluater.calculate_perplexity(test_loader, criterion)\n","print('Perplexity:', perplexity)\n","\n","seed_text = \"Start a discussion about coffee\"\n","gen_length = 50\n","\n","generated_text = evaluater.generate_text(seed_text, gen_length, data_processor_word.word_to_id, data_processor_word.id_to_word, 'word', device, temperature=1, top_p=0)\n","print(generated_text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3y0Ao6n_JyNh"},"source":["# Byte Pair Encoding"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mD28lvjzJePW"},"source":["# Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zz_8bRmhJjXS"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNCQnTJD947f/6xOExZiSCV","collapsed_sections":["6xiTrAxuAtfs","xrrp9aczAw0S"],"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
